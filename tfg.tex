% B.Sc. Thesis - Synthetic Differential Geometry
% Gaspar PÃ©rez Scornik <gasparperez2010@gmail.com>
%

\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{cite}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{xfrac}
\usepackage[a4paper,total={6.5in,8in}]{geometry}
\usepackage{fix-cm}
\usepackage[all]{xy}

\newtheorem{axiom}{Axiom}[section]
\setcounter{axiom}{-1}

\newtheorem{klaxiom}{KL Axiom}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]

\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{exmp}{Example}[defn]

\mathchardef\mhyph="2D
\newcommand{\abs}[1]{\lvert #1 \rvert} %Absolute value
\newcommand{\ddx}[2]{\frac{\partial #1}{\partial #2}} %partial derivative
\newcommand{\ddxk}[4]{\frac{\partial^{#1} #2}{\partial #3 \cdots \partial #4}} %k-th partial derivative
\newcommand{\ddxII}[3]{\frac{\partial^{2} #1}{\partial #2 \partial #3}} %2nd partial derivative
\newcommand{\farg}{-} %empty argument in function
\newcommand{\quot}[2]{#1/#2} %quotient of groups, modules, etc.
\newcommand{\sdgE}{\mathcal{E}}
\newcommand{\Q}{\mathbb{Q}}
%TODO: make this look better
\newcommand{\qalg}{\Q\mhyph\mathbf{Alg}}
\newcommand{\walg}{\operatorname W}
\renewcommand{\vec}{\underline} %markup for vectors
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\spec}{Spec}
\DeclareMathOperator{\rspec}{Spec_R}
\DeclareMathOperator{\id}{id}


\numberwithin{equation}{section}

\begin{document}

\section{The basic theory}

The axiomatic theory of Synthetic Differential Geometry begins by assuming a certain topos \( \sdgE \) exists. A topos is a category with certain properties which are meant to abstract the way in which the category of sets behaves. In fact, most naive set theoretic and logical notions have meaningful interpretation in terms of objects and morphisms of a topos. Thus, from this point on we will mainly omit the fact that we are working in a topos, and use standard set theoretic notation, giving only brief reminders now and then. 

\subsection{Axiomatics}

We begin with an object \( R \). We can think of \( R \) as an extension of the notion of the standard continuum, \( \mathbb{R} \). Thus \( R \) should be a commutative ring with unit. However, due to an axiom that we will shortly introduce, we cannot ask that \( R \) be a field. Later on, we will need to strengthen this requirement to, for example ``2:=1+1 is invertible''. But later on we may need that ``3 is invertible''. Instead of introducing these small axioms successively, we will take care of them succintly with our:

\begin{axiom}
  \label{ax0}
  \( R \) is a \( \Q \)-algebra.
\end{axiom}

With that out of the way, we proceed to introduce a central object of study, the ``infinitesimals''. These come in the form of nilpotent elements of \( R \). To be precise, let \( D = \{d\in R \mid d^2=0\} \). The (first version of the) defining axiom of SDG concerns \( D \), and as in all the literature we refer to it as the Kock-Lawvere axiom.

\begin{klaxiom}
  \label{KL1}
  For all \( f:D\to R \) there exist unique \( a,b\in R \) such that \( f(d) = a + bd\,\forall d\in D \)
\end{klaxiom}

Note that, in particular, \( a=f(0) \). Of course, this is a strong requirement. So strong in fact, that we will have to weaken our logic in order for the theory to be remotely interesting. This is because of the following proposition.

\begin{proposition}
  \label{0prop}
  \( R=\{0\} \)
\end{proposition}

\begin{proof}
  Let \( f:D\to R \) be defined by
  \begin{equation*}
    f(d) =
    \left\{ 
      \begin{aligned}
	1,& & d \neq 0 \\
	0,& & d = 0
      \end{aligned}
    \right.
  \end{equation*}
By the KL axiom \ref{KL1}, there exist unique \( a,b\in R \) such that \( f(d) = a + bd \) for all \( d \). Since \( a =  f(0) = 0 \), there exists \( b\in R \) such that \( f(d) = bd \) for all \( d \). Thus for non-zero \( d \) we have \( 1 = bd \). Squaring both sides yields \( 1 = 0 \), and since \( R \) is a ring this concludes the proof.
\end{proof}

However, the above proof relies on the ``fact'' that, for any \( x\in R \) we have either \( x = 0 \) or \( x\neq0 \). Indeed the well-definedness of the function \( f \) depends on this assertion. This is true in classical logic, as it is a simple application of the \textbf{Law of the Excluded Middle} (LEM):
\begin{equation*}
  \forall p\, p\vee \neg p
\end{equation*}
%TODO: comment about internal logic of topos is intuitionistic
To carry on with our theory, we see that we have to reject LEM. The above proof then fails, but of course just because of that we cannot conclude that the theory functions properly. To do so would by all means require exhibiting the category \( \sdgE \) explicitly. For now we will continue ignoring this, and develop the naive theory, knowing that we have to abstain from assuming LEM.

Without LEM, (\ref{0prop}) of course still contradicts (because we do want R to be a \( \Q \)-algebra) the statement
\begin{equation}
  \forall d\in D\,(d=0) \vee \neg (d=0)
  \label{eq:not0}
\end{equation}
In other words, its negation is true. One may be inclined to ``simplify'' the negation statement, leading to the apparent absurdity that
\begin{equation*}
  \exists d\in D\, \neg(d=0) \wedge \neg\neg (d=0)
\end{equation*}
Note that we haven't eliminated the double negation, since \( \neg\neg p\rightarrow p \) is equivalent to LEM. Still, the above would be a contradiction, since \( p\wedge \neg p \) is still false in intuitionistic logic. But, the first equivalence we used on the universally quantified statement (\ref{eq:not0}) also fails to be valid in intuitionistic logic (see \cite[p. 248]{fra84} for example).

%TODO: find a better proof of this
So what are the elements of \( D \)? For one they are not all zero, for if they were then every function \( d\mapsto ad, a\in R \) would be equal to the constant \( 0 \), but since each coefficient \( a \) is unique, we again reach the absurdity that every \( a\in R \) is the same (equal to zero). At the same time the negation of (\ref{0prop}) implies that not all \( d \) that aren't zero satisfy \( \neg(d=0) \). The consequence is the simple statement that
\begin{equation*}
  \exists d\in D \neg\neg(d=0)
\end{equation*}

The infinitesimals \( D \) are thus neither zero nor nonzero. This is a contradictory statement in classical logic, but it is precisely of the type of phrases that we should expect to appear if we weaken our logic to intuitionistic logic.

%TODO: cancellation of universally quantified d
\subsection{Elementary Calculus}

With our basic axiom scheme in place we can begin revisiting the classical notion of a derivative in this new context. We begin, as expected, with a function \( f:R\to R \). Fix \( x\in R \) and define a new function \( g:D\to R \) by
\begin{equation*}
  d\mapsto f(x+d)
\end{equation*}
By the KL axiom \ref{KL1} there are unique \( a,b\in R \) such that
\begin{equation*}
  \forall d\in D\, f(x+d) = f(x)+bd
\end{equation*}
(since \( g(0) = f(x) \)). This naturally leads to the following
\begin{defn}
  Let \( f:R\to R \). The \emph{derivative} of \( f \) at \( x \), denoted \( f'(x) \), is the unique \( b\in R \) such that \( f(x+d)=f(x)+bd\,\forall d\in D \).
  \label{def:1varder}
\end{defn}

Clearly this also allows us to define the derivative \emph{function} \( f':R\to R \). For instance, let us calculate the derivative of a simple polynomial function. Let \( f:x\mapsto x^2+x \) then
\begin{align*}
  f(x+d) & =  x^2+2xd + d^2 + x + d \\ 
         & =  x^2 + x + (2x+1)d
\end{align*}
by which \( f'(x)=2x+1 \). So far our ``formal'' calculus agrees with standard calculus. In fact, we have the following proposition:

\begin{proposition}
  Let \( f,g:R\to R \) and let \(\alpha\in R.\) The following hold:
  \begin{enumerate}
    \item \((f+g)' = f'+g'\)
    \item \((\alpha f)' = \alpha f'\)
    \item \((fg)' = f'g + fg'\)
  \end{enumerate}
\end{proposition}
\begin{proof}
  The proof is as simple as one could suspect, here we only prove the third identity as an example. We have:
  \begin{align*}
    f(x+d)g(x+d) & = (f(x)+f'(x)d)(g(x)+g'(x)d) \\
                 & = f(x)g(x) + (f'(x)g(x)+f(x)g'(x))d + f'(x)g'(x)d^2 \\
		 & = f(x)g(x) + (f'(x)g(x)+f(x)g'(x))d  
    \label{eq:prodrule}
  \end{align*}
  At a given \( x\in R \), this clearly holds for all \( d\in D \), giving us the result.
\end{proof}

Furthermore we have the Chain Rule:
\begin{proposition}
  Let \( f,g:R\to R \) be two functions. Then the derivative of the composite \( g\circ f \) is
  \begin{equation*}
    (f\circ g) = (f'\circ g)\cdot g'
  \end{equation*}
\end{proposition}
\begin{proof}
  Let \( x\in R \). Then
  \begin{equation*}
   (f\circ g)(x+d) = f(g(x)) + (f\circ g)'(x)d
  \end{equation*}
  by definition. Meanwhile, if we expand \( g(x+d) \) first:
  \begin{align*}
    (f\circ g)(x+d) & = f(g(x+d)) \\
                    & = f(g(x)+g'(x)d) \\
  \end{align*}
  Observe that \( g'(x)d\in D \), since \( (g'(x)d)^2 = g'(x)^2d^2 = 0 \). Now, \( f'(g(x)) \) is the unique coefficient satisfying
  \begin{equation*}
    f(g(x)+g'(x)d) = f(g(x)) + f'(g(x))g'(x)d
  \end{equation*}
\end{proof}

The reader may notice that these statements seem lazily worded. Normally, we would include in the hypotheses something like ``\textit{Let \( f,g:R\to R \) be} differentiable \textit{functions. Then} (some other function) \textit{is differentiable, and \dots etc.}'' We are not in fact forgetting hypotheses. The Kock-Lawvere Axiom \ref{KL1} actually implies that \textit{every} function from \( R \) to \( R \) is differentiable. This is easy to verify by noting that in the definition of the derivative (\ref{def:1varder}), no additional assumptions are made other than \( f \) being a function. As a direct consequence, every function from \( R \) to \( R \) is infinitely differentiable.

This leads us to ask if we also have Taylor expansions of functions. In classical calculus, a Taylor expansion of second order involves a second degree polynomial, and ``terms of order 3''. In our context, these are simply nilcube elements, i.e. \( \delta\in R : \delta^3 = 0 \). An example of such a nilcube is any \( d_1+d_2 \) where \( d_1,d_2 \) are both in \( D \). In effect,
\begin{equation*}
  (d_1+d_2)^3 = d_1^3 + d_2^3 + 3d_1^2d_2 + 3d_1d_2^2 = 0
\end{equation*}

Furthermore, if \( f:R\to R\) is a function, 
\begin{align*}
  f(x+d_1+d_2) & = f(x+d_1)+f'(x+d_1)d_2 \\
               & = f(x) + f'(x)d_1 + f'(x)d_2 + f''(x)d_1d_2
\end{align*}
and meanwhile,
\begin{align*}
  (d_1+d_2)^2 & = 2d_1d_2
\end{align*}
Joining the two together yields:
\begin{equation*}
  f(x+d_1+d_2) = f(x) + f'(x)(d_1+d_2) + \frac{f''(x)}{2}(d_1+d_2)^2
\end{equation*}

What we have just proven is the following proposition.
\begin{proposition}
  If \( f:R\to R \) is a function and \( d_1,d_2\in D \), then \( \delta = d_1+d_2 \) satisfies
  \begin{equation*}
    f(x+\delta) = f(x) + f'(x)\delta + \frac{f''(x)}{2}\delta^2
  \end{equation*}

\end{proposition}

This justifies the earlier heuristic of considering nilcubes as candidates for second order Taylor expansions. Unfortunately, there is no way to assert as of now that \textit{any} nilcube must be of the form \( d_1+d_2 \) with \( d_1,d_2\in D \). It is a partial result. In section {/placeholder1/} we will introduce Taylor expansions for every nilpotent element by way of an axiom that generalizes the KL axiom \ref{KL1}. Still, it serves as a nice exercise to prove the following, more general, Taylor formula.

\begin{proposition}
  Let \( f:R\to R \) be a function. Then for all \( n\in\mathbb N \) and \( \delta = d_1+\cdots+d_n \)
  \begin{equation*}
    f(x+\delta) = f(x) + f'(x)\delta + \frac{f''(x)}{2!}\delta^2 + \cdots + \frac{f^{(n)}}{n!}\delta^n
  \end{equation*}
  where \( x\in R \), \( d_1,\dots,d_n\in D \)
\end{proposition}

\begin{proof}
  To begin with, let us look at the powers of \( \delta \), that is, the usual multinomial formula:
  \begin{equation*}
    \delta^k = (d_1+\cdots+d_n)^k = \sum_{i_1+\cdots+i_n=k}\left( k\atop i_1,\dots,i_n \right)\prod_{r=1}^{n}d_r^{i_r}
  \end{equation*}
  Recall that the \( d_r \) are in \( D \), so only the only non-zero summands will be those with each \( d_r \) raised to either 1 or 0. That is, choosing a subset of the \( i_r \) to be 1, and the rest 0. In that case the multinomial coefficients are simply \( k! \), giving us
  \begin{equation*}
    \delta^k = \sum_{I\subset \{1,\dots,n\}\atop \abs{I}=k}k!\prod_{t\in I}d_t
  \end{equation*}
  in other words, the \( k \)-\textit{th} elementary symmetric polynomial of \( n \) variables (multiplied by \( k! \)). Denote this by \( e_k(X_1,\dots,X_n) \), and convene \( e_0 \equiv 1 \) and \( e_k(X_1,\dots,X_n) = 0 \) if \( k>n \). We proceed inductively:
  % [TODO] Fix this equation
  \begin{align}
    \begin{split}
      f(x+\delta) & = f(x+d_1+\cdots+d_n) \\[10pt]
                  & = f(x+d_1+\cdots+d_{n-1})+f'(x+d_1+\cdots+d_{n-1})d_n \\[10pt]
		  & = \sum_{i=0}^{n-1}\frac{f^{(i)}(x)}{i!}i!e_i(d_1,\dots,d_{n-1}) + d_n\sum_{i=0}^{n-1}\frac{f^{(i+1)}(x)}{i!}i!e_i(d_1,\dots,d_{n-1}) \\[10pt]
                  & = \sum_{i=0}^{n-1}f^{(i)}(x)\left( e_i(d_1,\dots,d_{n-1})+d_ke_{i-1}(d_1,\dots,d_{n-1})\right) + d_kf^{(n)}(x)e_{k-1}(d_1,\dots,d_{k-1})
    \end{split}
    \label{eq:ntaylor}
  \end{align}
It's now useful to use the following recursion that elementary symmetric polynomials satisfy:
\begin{equation*}
  e_k(X_1,\dots,X_n) = e_{k}(X_1,\dots,X_{n-1}) + X_{n}e_{k-1}(X_1,\dots,X_{n-1})
\end{equation*}
Finally, observe that \( e_{k-1}(d_1,\dots,d_{k-1}) \) is just \( d_1d_2\cdots d_{k-1} \), meaning that \( d_ke_{k-1}(d_1,\dots,d_{k-1}) = e_k(d_1,\dots, d_{k-1},d_k) \). With these two identities, \ref{eq:ntaylor} becomes:
\begin{equation*}
  \sum_{i=0}^{n}f^{(i)}(x)e_i(d_1,\dots,d_k)= \sum_{i=0}^n \frac{f^{(i)}(x)}{i!}\delta^j
\end{equation*}
\end{proof}

We'd do well to note that, for \( n\geq k+1 \), \( \delta^n \) is 0. The above Taylor formula is of course still valid for any \( k \) and \( n \), but the terms are all zero after \( k+1 \). We again find a unique characterization of all functions on a certain set of nilpotents. This property will be stated in section {/placeholder1/} as a general axiom.

\subsection{Calculus of several variables}
We now take the usual course in calculus, which is to generalize the previous study to functions of more than one variable, i.e. \( R^n\to R \), and further on functions \( E\to V \) where \( E \) and \( V \) are ``vector spaces'' in a sense that will be made precise.

\subsubsection{Scalar functions}
Let \( f:R^n\to R \) be a function, and \( r=(r_1,\dots,r_n)\in R^n \). As one would expect, we calculate the partial derivatives by adding an infinitesimal increment along a single coordinate direction. That is, let \( g: D\to R \) be defined by
\begin{equation*}
  d\mapsto f(r_1+d,\dots,r_n)
\end{equation*}
By the KL axiom \ref{KL1}, there exists a unique \( b\in R \) such that
\begin{equation*}
  f(r_1+d,\dots,r_n) = f(r) + bd
\end{equation*}
We define \( \ddx{f}{x_1}(r_1,\dots,r_n)\) as \( b \), which simultaneaously defines a function \( \ddx{f}{x_1}:R^n\to R \) Similarly, we define \( \ddx{f}{x_2},\dots,\ddx{f}{x_n} \). By iterating the process we obtain higher partial derivatives, denoted
\begin{equation*}
  \ddxk{k}{f}{x_{i_1}}{x_{i_k}}
\end{equation*}

A nice result is a parallel of Schwarz' theorem of the interchangeability of partial derivatives.

\begin{proposition}
  Let \( f:R^n\to R \) be a function. Then for any \( 1\leq i,j\leq n \)
  \begin{equation*}
    \ddxII{f}{x_i}{x_j}= \ddxII{f}{x_j}{x_i}
  \end{equation*}
  \label{prop:schwarz}
\end{proposition}
%TODO: this part looks horrible
The previous result follows directly from the following lemma which generalizes the second-order Taylor expansion to two dimensions.
\begin{lemma}
  Let \( f:R^n \to R \) be a function. Then for all \( (d_1,d_2)\in D\times D \)
  \begin{align*}
    f(r_1,\dots,r_i+d_1,\dots,r_j+d_2,\dots,r_n) = f(x_1,\dots,x_i,\dots,x_j+d_2,\dots,x_n) + \\
    \qquad + \ddx{f}{x_i}(x_1,\dots,x_i,\dots,x_j,\dots,x_n)d_1 + \ddxII{f}{x_i}{x_j}(x_1,\dots,x_n)d_2d_1 
  \end{align*}
\end{lemma}

\begin{proof}
  Apply the definition of the partial derivative in \( x_i \), and succesively in \( x_j \)
  \begin{align*}
    f(r_1,\dots,r_i+d_1,\dots,r_j+d_2,\dots,r_n) & = f(x_1,\dots,x_i,\dots,x_j+d_2,\dots,x_n) + \\
                                                 & \qquad\qquad + \ddx{f}{x_i}(x_1,\dots,x_i,\dots,x_j+d_2,\dots,x_n)d_1 \\
                                                 & = f(x_1,\dots,x_n) + \ddx{f}{x_i}(x_1,\dots,x_n)d_1 + \ddxII{f}{x_i}{x_j}(x_1,\dots,x_n)d_2d_1
  \end{align*}
  and \( f(x_1,\dots,x_n), \ddx{f}{x_i}(x_1,\dots,x_n), \ddx{f}{x_j}(x_1,\dots,x_n), \ddxII{f}{x_i}{x_j}(x_1,\dots,x_n)  \) are the unique coefficients that satisfy this for universally quantified \( (d_1,d_2)\in D \).
\end{proof}

On the other hand, exchanging \( d_1 \) and \( d_2 \) (and commuting products and sums) in the above equations yields the same conclusion for \( \ddxII{f}{x_j}{x_i}(x_1,\dots,x_n) \). Since they are unique they must equal each other, proving (\ref{prop:schwarz}). By induction we also obtain that the order in which we differentiate higher partial derivatives does not matter.

\subsection{Vector functions}
We will now examine functions between \( R \)-modules. However, for a general \( R \)-module \( V \), it does not follow from the KL axiom (\ref{KL1}) that a version of it holds for functions \( D\to V \). In this case what we do is simply restrict our attention to those \( R \)-modules where this is the case. This leads to the following definition:

%TODO: example of R-module that isn't Euclidean.
\begin{defn}
  An \( R \)-module \( V \) is said to be a \emph{Euclidean \( R \)-module} if the vector form of the KL axiom holds. That is, for any function \( f: D\to V \),
  \begin{equation*}
    \exists! \, \vec a,\vec b\in V \text{ such that } f(d) = \vec a + d\vec b \,\forall d\in D
  \end{equation*}
  (again \( \vec a \) is evidently \( f(0) \))
\end{defn}

This may seem like a very ad-hoc definition, but we will encounter many Euclidean \( R \)-modules naturally. For example we have the following lemma.

\begin{lemma}
  \leavevmode
  \begin{enumerate}
    \item \( R^n \) is a Euclidean \( R \)-module.
    \item For any object \( X \), and Euclidean \( R \)-module \( V \), the exponential \( V^X \) is a Euclidean \( R \)-module. 
  \end{enumerate}
  \label{lm:Emod}
\end{lemma}

\begin{proof}
  \leavevmode
  \begin{enumerate}
    \item This is evident since a function \( f:D\to R^n \) is uniquely determined by each of its component functions. We let \( f_i = \pi_i \circ{f}  \) where \( \pi_i:R^n\to R \) is the \( i \)-\textit{th} coordinate projection. Then \( \vec a=(a_1,\dots,a_n), \vec b=(b_1,\dots,b_n) \) are the unique coefficients in the claim. Here each \( a_i,b_i \) is obtained by applying the KL axiom to \( f_i \).
    \item First of all, \( V^X \) is an \( R \)-module by the pointwise sum of maps. Let \( f:D\to V^X \) be a function. This defines, for each \( x\in X \), a function \( g(x):D\to V \) by
    \begin{equation*}
      d\mapsto f(d)(x)
    \end{equation*}
    since \( V \) is Euclidean, there exist unique \( a(x), b(x) \) such that
    \begin{equation*}
      f(d)(x) = \vec a(x) + d\vec b(x)\,\forall d\in D
    \end{equation*}
    Evidently, varying \( x \) defines functions \( \vec a,\vec b:X\to V \), which are unique such that \( f(d) = \vec a + d\vec b \,\forall d\in D\)
  \end{enumerate}
\end{proof}

Additionally, it's clear that any \( V \) which is isomorphic to \( R^n \) as an \( R \)-module is too Euclidean. In \cite{kock10} for example, it begins directly with this notion, calling them ``finite dimensional vector spaces''. Another fundamental example of a Euclidean \( R \)-module that we'll study are tangent spaces, in section {/placeholder2/}.

For now let us go back to doing calculus. The Euclidean structure allows one to define directional derivatives, as is done in \cite{lav96}, for example.
\begin{defn}
  Let \( V,E \) be Euclidean \( R \)-modules, \( f:V\to E \) a function and \( \vec u, \vec a\in V \). The derivative of \( f \) at \( \vec a \) in direction \( \vec u \) is the unique \( \vec b\in E \) such that
  \begin{equation*}
    \forall d\in D,\, f(\vec a + d\vec u) = f(\vec a) + d\vec b
  \end{equation*}
  We denote this by \( \partial_{\vec u}f(a) \). 
\end{defn}

We note that \( \partial_{(\farg)}f(\vec a) \) is a linear function. In other words, for all \( \lambda,\mu \in R\),
\begin{equation*}
  \partial_{\lambda \vec u + \mu \vec v}f(\vec a) = \lambda\partial_{\vec u}f(\vec a) + \mu\partial_{\vec v}f(\vec a)
\end{equation*}
The proof is a straightforward excercise (one may consult \cite[p. 13]{lav96}).

If \( V \) is finitely generated, i.e. \( V = \spn{\{e_1,\dots,e_n\}} \), then one can define
\begin{equation*}
  \ddx{f}{x_i}(\vec a) = \partial_{e_1}f(\vec a)
\end{equation*}
and if \( \vec u = \sum_{i=1}^{n}{u_ie_i} \) then by linearity
\begin{equation*}
  \partial_{\vec u}f(\vec a) = \sum_{i=1}^{n}\ddx{f}{x_i}u_i
\end{equation*}

Finally, the familiar total differential makes an appearance here too.

\begin{defn}
  Let \( f:V\to E \) be a function. The \emph{differential} of \( f \) at \( \vec a\in V \) is the function \( df(\vec a):V\to E \) defined by
  \begin{equation*}
    \vec u\mapsto \partial_{\vec u}f(\vec a)
  \end{equation*}
\end{defn}


\section{The general KL axiom}

\subsection{A closer look at the first axiom} \label{ax1re}

Let \( (a,b)\in R\times R \). To this pair we can associate the function
\begin{equation*}
  f:D\to R
  \atop
  d\mapsto a + bd
\end{equation*}

In this manner we obtain a map
\begin{equation*}
  \alpha : R\times R\to R^D
\end{equation*}

Axiom \ref{KL1} can then be succintly stated by demanding that \( \alpha \) be bijective. Note that the \( R \)-module structure is also preserved, so that \( \alpha \) is an \( R \)-module isomorphism. Furthermore, \( R^D \) has a natural \( R \)-algebra structure given by the pointwise product of maps:

\begin{align}
  (a_1 + b_1d)(a_2 + b_2d) & = a_1a_2 + (a_1b_2 + b_1a_2)d + b_1b_2d^2 \\
                           & = a_1a_2 + (a_1b_2 + b_1a_2)d
  \label{R-alg}
\end{align}

As such, \( R\times R \) does not possess an \( R \)-algebra structure, but if we define a product by the above formula, that is
\begin{equation*}
  (a_1,b_1)\cdot(a_2,b_2) = (a_1a_2,a_1b_2 + b_1a_2)
\end{equation*}
then \( \alpha  \) is an \( R \)-algebra isomorphism.

It will be helpful for motivating the forthcoming definitions to state this in yet another way. The previous structure on \( R\times R \) is nothing more than the natural \( R \)-algebra on
\begin{equation*}
  W = \quot{R[X]}{(X^2)}
\end{equation*}
thus there is an isomorphism of \( R \)-algebras
\begin{equation*}
  W \stackrel{\alpha}{\cong} R^D
\end{equation*}

In the following section we will generalize this idea.

\subsection{Weil Algebras}

The infinitesimals \( D \) are one among many other ``small objects'' in SDG, called \emph{Weil algebras}, due to AndrÃ© Weil. We will use the general definition as per \cite{bun17}.

\begin{defn}
  A \emph{Weil algebra} \( W \) is a \( \Q \)-algebra together with a morphism
  \begin{equation*}
    \pi: W\to\Q
  \end{equation*}
  such that \( W \) is a local ring with maximal ideal \( I=\pi^{-1}(0) \) with \( I \) nilpotent and such that \( W \) is finite dimensional as a \( \Q \) vector space. A homomorphism of Weil algebras \( f:W_1\to W_2 \) is thus an algebra homomorphism sending the maximal ideal of \( W_1 \) to that of \( W_2 \).
\end{defn}



It will do to explore some simple consequences of this definition.

\begin{lemma}
  Any Weil algbra \( W \) may be finitely presented, that is, \( W \) is isomorphic to
  \begin{equation*}
    \Q[X_1,\dots,X_n]/(P_1,\dots,P_s)
  \end{equation*}
  where \( P_1,\dots P_s \) are polynomials of \( \Q[X_1,\dots,X_n] \).
  \label{lm:finpr}
\end{lemma}

\begin{proof}
  Let \( e_1,\dots,e_n \) be a \( \Q \)-basis of \( W \). The algbra structure is then determined by the constants \( \gamma_{ij}^k \) given by
  \begin{equation*}
    e_i\cdot e_j = \sum_{k=1}^n \gamma_{ij}^ke_k
  \end{equation*}
  in other words, the kernel of the surjection
  \begin{equation*}
    E: \Q[X_1,\dots,X_n]\to W
  \end{equation*}
  given by \( X_k\mapsto e_k \) is the ideal generated by the polynomials
  \begin{equation*}
    X_iX_j - \sum_{k=1}^n\gamma_{ij}^kX_k
  \end{equation*}
  With \( 1\leq i,j\leq n \). Thus \( W \) is isomorphic to \( \Q[X_1,\dots,X_n]/\ker E \) with \( \ker E \) finitely generated.
\end{proof}

Naturally, there is no reason for \( X_1,\dots,X_n \) to be a minimal set of generators. In \cite{lav96}, this minimal number of generators is referred to as the \emph{breadth} of a Weil algebra, and the smallest power that annihilates the maximal ideal as the \emph{height}.

%TODO:prove this
That a Weil algebra \( W \) is finite dimensional over \( \Q \) means that it is isomorphic to \( \Q^n \) with a certain product given by \( \gamma_{ij}^k \), for some \( n \). If \( A \) is any other \( \Q \)-algebra, then so can \( A^n \) be endowed with a product by letting \( e_ie_j = \gamma_{ij}^ke_k \) where \( e_l = (0,\stackrel{(l)}{\dots},1,\dots,0) \), making \( A^n \) an \( A \)-algebra. This structure is manifestly dependent on the \( e_l \). However, it does not depend on the presentation of \( W \). This algebra structure on \( A^n \) is denoted \( A[W] \). For instance, the \( R \)-algebra on \( R\times R \) from (\ref{R-alg}) arises in this way as \( R[W] \), where
\begin{equation*}
  W = \Q[X]/(X^2)
\end{equation*}
If we repeat the steps that we took to obtain a presentation of a Weil algebra \( W \cong \mathbb{Q}[X_1,\dots,X_n]/(P_1,\dots,P_s) \) then it's clear that for any other \( \mathbb{Q} \)-algebra \( A \), the algebra \( A[W] \) is also presented as \( A[X_1,\dots,X_n](P_1,\dots,P_s) \).

It's worth mentioning that in \cite{lav96}, the author defines Weil algebras directly as objects which according to our definition arise as \( R[W] \) with \( W \) a Weil algebra as defined above. The distinction is that \( R[W] \) need not be a local ring (for instance, (\ref{R-alg}) has the ideal \( ((0,a)) \) with \( a\in R \) which is not maximal since any element \( (d,0) \) with \( d\in D \) is in its complement, but it is not a unit. However this only changes the phrasing involved for the general KL axiom (the goal of this section), and not the content.

\subsection{Spectra of Weil Algebras}

The final piece involved in the statement of the general KL axiom is that of the \emph{spectrum} of a Weil algebra.
\begin{defn}
  Let \( W \) be a Weil algebra, and \( C \) be an \( R \)-algebra. If \( W \) is presented as 
  \begin{equation*}
    \Q[X_1,\dots,X_n]/(P_1\dots,P_s)
  \end{equation*}
  the \emph{spectrum} of \( W \) in \( C \) is
  \begin{equation*}
    \spec_C{W} = \{(a_1,\dots,a_n)\in C^n \mid P_j(a_1,\dots,a_n) = 0, j=1,\dots,s\} 
    \label{def:spec}
  \end{equation*}
\end{defn}
It is not difficult but it is prudent to check that this is well defined. In fact we shall prove that \( \spec_C(\farg) \) is functorial. Note that elements of \( \spec_C(W) \) can be ``evaluated'' at by classes in \( W \), since two representatives differ by an element of \( I=(P_1,\dots,P_j) \), but every polynomial in \( I \) is zero on \( \spec_C(W) \) by definition. We shorten such an evaluation, \( (P+I)(a) \), simply to \( P(a) \). 

Let \( W_1, W_2 \) be Weil algebras, with
\begin{align*}
  W_1 &\cong \Q[X_1,\dots,X_n]/I \\
  W_2 &\cong \Q[Y_1,\dots,Y_n]/J
\end{align*}

Now let \( f:W_1\to W_2 \) be a homomorphism of Weil algebras. Define
\begin{equation*}
  \spec_C(f):\spec_C(W_2)\to \spec_C(W_1)
\end{equation*}
by
\begin{equation*}
  \spec_C(f)(b_1,\dots,b_m) = (a_1,\dots,a_n)
\end{equation*}
where
\begin{equation*}
  a_i = f(X_i)(b_1,\dots,b_m)
\end{equation*}

We have
\begin{enumerate}
  \item \(\spec_C(\farg)\) preserves identities.
    In effect, the identity on a Weil algebra \( \id_W \) sends \( X_i \) to \( X_i \), and since \( X_i(b_1,\dots,b_m) = b_i \) so is \( \spec_C(\id_W) \) the identity on \( \spec_C(W) \).
  \item \(\spec_C(g\circ f) = \spec_C(f)\circ \spec_C(g)\), where defined. The proof is a simple verification.
\end{enumerate}

By virtue of the (contravariant) functoriality we get as a corollary that isomorphic Weil algebras induce a bijection on their spectra. With these definitions in place we may state the complete version of the KL axiom.

\subsection{The KL Axiom}

Let \( W\cong \mathbb{Q}[X_1,\dots,X_n]/I \) be a Weil algebra. Earlier we observed that we can evaluate (classes of) polynomials in \( W \) at elements of \( \spec_R(W) \) (just replace \( C \) with \( R \)). In other words each element of \( W \) defines a mapping \( \spec_R(W)\to R \)
\begin{equation*}
  W\to R^{\spec_R(W)}
\end{equation*}

In the same manner we also obtain a mapping
\begin{equation*}
  \alpha : R[W]\to R^{\spec_R(W)}
\end{equation*}

Again given by sending \( (p+I)\in R[W] \) to the map \( a\mapsto p(a) \). It is of course an algebra homomorphism. The KL Axiom asserts that it is bijective.
\begin{axiom}[KL]
  Let \( W\cong \mathbb{Q}[X_1,\dots,X_n]/I \) be a Weil algebra. Then the map
  \begin{equation*}
    \alpha : R[W]\to R^{\spec_R(W)}
  \end{equation*}
  given by \( p+I \mapsto (a\mapsto p(a)) \) is an \( R \)-algebra isomorphism.
  \label{ax:genKL}
\end{axiom}

By asserting this axiom we obtain many of the propositions in the first part of this monograph in a stronger version, and further generalizations. But before looking at those examples we'll note that the first KL axiom given is too a consequence of axiom \ref{ax:genKL}. This can be seen simply by applying the axiom to the Weil algebra \( \mathbb{Q}[X]/(X^2) \). The result is the equivalent version of axiom \ref{KL1} that we had already observed in section \ref{ax1re}.

What the general KL axiom provides is essentially, given a particular set of ``small'' elements of \( R \), a correspondence between functions from that set to \( R \) with a particular finite dimensional \( R \)-algebra. These ``small'' elelements are the objects \( \spec_R(W) \) for some Weil algebra \( W \).  We refer to them as ``small'' because they are meant to be a rigorization of the historically nebulous concept of ``infinitesimals''. We first introduced nilsquares (\( \spec_R(Q[X]/(X^2)) \)), on which all functions are affine, giving us first order derivatives. The Taylor formulas that came afterwards were restricted, however, to sums of elements of \( D \) and not any nilpotent element of \( R \). Since other nilpotents are too spectra of certain Weil algebra, we now have Taylor formulae for these, given by axiom \ref{ax:genKL}. We'll look at a few such spectra, study the KL axiom in regards to them and at the same time introduce their common nomenclature.

\begin{itemize}
  \item \( D_k := \spec_R(W_{k+1}) \) with \( W_{k+1} = \mathbb{Q}[X]/(X^{k+1}) \). These are elements of \( R \) whose \( (k+1) \)-th power is zero (in particular \( D_2 = D \)). One can check that \( W_{k+1} \) is isomorphic to the the set \( \{a_0+a_1\epsilon + \dots + a_k\epsilon^k\ \mid a_i\in R\} \) with \( \epsilon \) denoting the equivalence class of \( X \) in \( W_{k+1} \). By axiom \ref{ax:genKL} the set of functions \( D_k\to R \) are isomorphic as an \( R \)-algebra to the algebra \( W_{k+1} \). Another way of saying this is that:
    \begin{proposition}
      For all functions \( g:D_k\to R \) there exist unique coefficients \( a_0,\dots,a_k\in R \) such that
      \begin{equation*}
	 g(\delta) = a_0 + a_1\delta + \dots + a_k\delta^k \quad \forall\delta\in D_k
      \end{equation*}
    \end{proposition}
    And as an immediate consequence we have that, for any \( f:R\to R \) there exist unique coefficients \( a_0,\dots,a_k\in R \) such that
    \begin{equation*}
      f(x+\delta) = a_0 + a_1\delta + \dots + a_k\delta^k \quad \forall \delta\in R\, :\, \delta^{k+1}=0
    \end{equation*}
    That is, we have Taylor formulas of all orders (and one can check that the \( a_i \) are precisely the Taylor coefficients).

  \item \( (D_k)^n := \spec_R((W_{k+1})^n) \) where \( (W_{k+1})^n \) just means the cartesian product with itself \( n \) times (and so does taking the spectrum of the product of \( W_k \) coincide with the product of \( D_k \)). This is a Weil algebra, and it is presented by \( \mathbb{Q}[X_1,\dots,X_n](X_1^{k+1},\dots,X_n^{k+1}) \) . The general KL axiom applied to this particular algebra is what yields higher dimensional Taylor formulae. We state it now without proof (a tedious but simple combinatorial exercise).
    \begin{proposition}
      For any function \( f:R^n\to R \),
      \begin{equation*}
	f( \vec{x} + \vec{\delta} ) = \sum_{\alpha \leq k}{\frac{\vec{\delta}}{\alpha!}\cdot\frac{\partial^{\abs\alpha}f}{\partial x^\alpha}(\vec{x})}\quad \forall \delta : \delta^{k+1}=0
      \end{equation*}
    \end{proposition}
    where we're using the usual multi-index notation - if \( \alpha=(\alpha_1,\dots,\alpha_n) \) then \( \abs\alpha = \alpha_1+\dots+\alpha_n \), \( \alpha! = \alpha_1!\cdot\dots\cdot\alpha_n! \) and \( \frac{\partial^{\abs\alpha}f}{\partial x^\alpha}=\frac{\partial^{\abs\alpha}f}{\partial x^{\alpha_1}\dots\partial x^{\alpha_n}} \). The partial derivatives are defined in the same way as before.
  \item \( D(n) := \spec_R(W(n)) \) where \( W(n) = \Q[X_1,\dots,X_n]/(\{X_iX_j\}_{1\leq i,j \leq n}) \). A simpler way of writing this is \( D(n) = \{(d_1,\dots,d_n)\subset R^n\mid \text{the product of any two \( d_i,d_j \) is zero}\} \).
  \item \( D_k(n) := \spec_R(W_k(n)) \) where \( W_k(n) = \Q[X_1,\dots,X_n]/(\{X_{i_1}\cdots X_{i_k}\}_{1\leq i_1,\dots,i_k\leq n}) \). Again these are the elements of \( R^n \) such that the product of any \( k \) of their components is equal to zero.
\end{itemize}

There are some notable inclusions:

\begin{align*}
  D_k(n)  &\subset D_l(n)             \text{ iff k\(\leq\) l} \\
  D_k(n)  &\subset (D_k)^n            \\
  (D_k)^n &\subset D_{n\cdot k}(n)   
\end{align*}

\section{Microlinearity}

\subsection{A simple example}

We begin by observing a few specific cases. Let
\begin{equation*}
   D\times D \to D 
\end{equation*}
be the multiplication map, i.e. \( (d_1,d_2)\mapsto d_1d_2 \). Nothing in our theory suggests that this map should be surjective, but for many purposes it suffices to have the following property:

\begin{proposition}
  If \( f_1,f_2:D \to R \) verify that, for each \( d_1,d_2\in D,\, f_1(d_1d_2) = f_2(d_1d_2)  \) then \( f_1=f_2 \).
\end{proposition}

That is, it suffices to know any function \( f:D\to R \) on products of elements of \( D \). This is referred to in \cite{kock06} as ``\emph{\( R \) thinks that the multiplication : \( D\times D\to D \) is surjective}''.

\begin{proof}
  Define \( g = f_1-f_2 \). By our hypothesis \( g \) is identically zero on all elements \( d_1d_2 \) with \( d_1,d_2\in D \). By the KL axiom (since the previous section this refers to axiom {//placeholder//}, but in this case axiom \ref{KL1} also suffices), there exist unique \( a,b\in R \) such that
  \begin{equation*}
    g(d)=a + bd\quad \forall d\in D 
  \end{equation*}
  On the one hand \( a=g(0)=g(0\cdot 0) = 0 \), so that \( g(d)=bd \). Thus, for all \( d_1,d_2\in D \) we have \( 0 = g(d_1d_2) = bd_1d_2 \), or in other words that \( bd_1d_2=0 \) for all \( d_1,d_2\in D \), which means that \( b=0 \).
\end{proof}

\subsection{A slightly more interesting example}

Consider two functions \( f,g:D\to X \) such that \( f(0)=g(0) \), where \( X \) is some set (object of \(  \sdgE) \). Here there is no reason to assume that this will define a map \( D(2)\to X \). It will be the case, however, if \( X \) is \( R \).

\begin{proposition}
  Let \( f,g:D\to R \) be functions such that \( f(0)=g(0) \). Then there exists a unique function \( h:D(2)\to R \) such that \( h(d,0) = f(d) \) and \( h(0,d)=g(d) \) for all \( d\in D \).
  \label{prop:d2}
\end{proposition}

\begin{proof}
  Let \( a_0 = g(0)=f(0) \). Then we have that for all \( d\in D \),
  \begin{align*}
    f(d) &= a_0 + a_1d \\
    g(d) &= a_0 + b_1d \\
  \end{align*}
  Thus, we simply define \( h \) by
  \begin{equation*}
    h(d_1,d_2) = a_0 + a_1d_1 + b_1d_2
  \end{equation*}
  This clearly satisfies the existence requirements. The Uniqueness is a consequence of the KL axiom. Let \( k \) be another function that satisfies the hypotheses. By the KL axiom applied to \( D(2) \),
  \begin{equation*}
    k(d_1,d_2) = \alpha_0 + \alpha_1d_1 + \alpha_2d_2
  \end{equation*}
  for unique \( \alpha_i \). By \( k(d,0)=f(d) \) we obtain \( \alpha_0=a_0 \) and \( \alpha_1 = a_1 \). Similarly \( \alpha_2=b_1 \). Since the \( \alpha_i \) are unique and determine \( k \), we get \( k=h \) (if preferred we could have concluded at the very definition of \( h \), since the KL axiom asserts that functions on \( D(2) \) are defined as such - the argument has simply been explicited a bit further here).

\end{proof}

\subsection{Perceived colimits}

The previous examples can be stated in diagrammatic form, which will then lend itself to a generalization in terms of (co)limits. We'll focus on the second example. Consider the following commutative diagram:

\begin{equation}
  \xymatrix{
    {\{0\}} \ar[d]_0 \ar[r]^0   & D \ar[d]^{i_2} \\
    D \ar[r]_{i_1}              & D(2)
  }
  \label{dg:pushout}
\end{equation}

Where \( i_1 \) and \( i_2 \) are the inclusion maps \( i_1(d)=(d,0),\, i_2(d)=(0,d) \) and \( 0 \) is the constant zero map. The previous observation that two maps \( f,g:D\to X \) do not have to define a map \( D(2)\to X \) is equivalent to saying that diagram \ref{dg:pushout} is not a pushout. But, if we apply the \( R^{(\farg)} \) functor to it, the result is:

\begin{equation*}
  \xymatrix{
    R^{\{0\}}       & R^D \ar[l]_{R^0}                           \\
    R^D \ar[u]^{R^0} & R^{D(2)} \ar[u]_{R^{i_2}} \ar[l]^{R^{i_2}} 
  }
  \label{dg:pullback}
\end{equation*}

\begin{proposition}
  Diagram \ref{dg:pullback} is a pullback.
  \label{prop:pullback}
\end{proposition}

%TODO:make sure of this and add to appendix
\begin{proof}
  First we will make the diagram a little neater. Firstly, \( R^{\{0\}} \) is isomorphic to \( R \). The map \( R^0 \) Takes \( f:D\to R \) and sends it to \( f\circ 0 \), which we simply identify with \( f(0) \) the same way we identified \( R^{\{0\}} \) with \( R \). Likewise, the map \( R^{i_1} \) sends \( g:D(2)\to R \) to \( g\circ i_1 \). Thus, for \ref{dg:pullback} to be a pullback, we'd need that the set \( R^D(2) \) be in bijection with the set of pairs \( f,g\in R^D \) such that \( f(0)=g(0) \). But this is precisely what we proved in proposition \ref{prop:d2}.
\end{proof}

How we refer to this phenomenon (or how it is often referred to) is \emph{``R perceives diagram \ref{dg:pushout} as a pushout}. This is of course generalizes, as we will see shortly. To do so we will give a few definitions first.

\begin{defn}
  Let \( \walg \) be the category of Weil algebras (a subcategory of the category of \( \Q \)-algebras \( \qalg \)). A \emph{good limit} of Weil algebras is a limit \( \left(L\stackrel{f_i}{\longrightarrow}D_i\right)_{i\in I} \) in \( \qalg \) which is also a limit in \( \walg \). That is, the morphisms in the diagram defining \( L \) must be Weil algebra homomorphisms, and so must the projections \( f_i \).
\end{defn}

\begin{defn}
  A diagram in \( \sdgE \) is said to be a (finite) \emph{quasi colimit} if it is the image under the functor
  \begin{equation*}
    \spec_R(\farg):\walg\to\sdgE
  \end{equation*}
  of a good finite colimit in \( \walg \).
\end{defn}

\begin{defn}
  An object \( X \) is said to perceive a quasi colimit as a colimit if the functor
  \begin{equation*}
    X^{(\farg)}:\sdgE\to\sdgE
  \end{equation*}
  takes said quasi colimit into a limit (of \( \sdgE \)).
\end{defn}

\begin{exmp}
  The following diagram is a good colimit of Weil algbras (it is a pushout in \( \qalg \), and the morphisms are Weil algebra homomorphisms).
  \begin{equation}
    \xymatrix{
      {\Q}                   & {\Q[X]/(X^2)} \ar[l]^0 \\
      {\Q[X]/(X^2)} \ar[u]^0 & {\Q[X,Y]/(X^2,Y^2,XY)} \ar[u]^{p_2} \ar[l]^{p_1}
    }
    \label{dg:goodlimex}
  \end{equation}
  where \( p_1(X)=X, p_1(Y)=0, p_2(X)=0 \), and \( p_2(Y)=X \). Via the \( \spec_R(\farg) \) functor this is taken to
  \begin{equation*}
    \xymatrix{
      {\{0\}} \ar[d]_0 \ar[r]^0 & D \ar[d]^{i_2} \\
      D \ar[r]_{i_1}            & D(2)
    } 
  \end{equation*}
  which is the same as diagram \ref{dg:pushout}. Thus, since diagram \ref{dg:goodlimex} is an example of a good finite limit, diagram \ref{dg:pushout} is a finite quasi colimit. Furthermore, \( R \) perceives \ref{dg:pushout} as a limit, as observed in proposition \ref{prop:pullback}.
\end{exmp}

%TODO: add other places where it is useful, if they arise
For plenty more examples, one should look at \cite{lav96}. The objective of these definitions are to state the upcoming proposition, which generalizes the previous observation that \emph{``R perceives\dots etc''}. The result will be of use in section {//placeholder//} as a smoothness condition.

\begin{proposition}
  \( R \) perceives finite quasi colimits as colimits. Conversely, if \( R \) perceives a diagram as a colimit, it is a quasi colimit. 
  \label{prop:Rperc}
\end{proposition}

We'll need a simple result previously, in the form of the following

%TODO:proof
\begin{lemma}
  Let 
  \begin{equation*}
   \left(W_i\stackrel{p_i}{\longleftarrow}W_L\right)_{i\in I}
  \end{equation*}
  be any limit of Weil algebras. Then the diagram
  \begin{equation*}
    \left(R[W_i]\stackrel{p_i}{\longleftarrow}R[W_L]\right)_{i\in I}
  \end{equation*}
  is a limit of \( R \)-algebras.  
  \label{lm:Rbracket}
\end{lemma}

With that, we can prove the proposition.

\begin{proof}[Proof of proposition \ref{prop:Rperc}]
  Let \( \left(L\stackrel{f_i}{\longrightarrow}D_i\right)_{i\in I} \) be a finite quasi colimit. That is, we may write the diagram as
  \begin{equation}
    \left(\spec_R(W_L)\stackrel{\spec_R(p_i)}{\longrightarrow}\spec_R(W_i)\right)_{i\in I}
    \label{dg:fquasicolt}
  \end{equation}
  where
  \begin{equation*}
   \left(W_i\stackrel{p_i}{\longleftarrow}W_L\right)_{i\in I}
  \end{equation*}
  is some good finite limit of Weil algebras. We need to prove that diagram \ref{dg:fquasicolt} is taken to a limit by the functor \( R^{(\farg)} \). Under this functor, the resulting diagram is
  \begin{equation}
    \left(R^{\spec_R(W_L)}\stackrel{R^{\spec_R(p_i)}}{\longrightarrow}R^{\spec_R(W_i)}\right)_{i\in I}
    \label{dg:Rfqc}
  \end{equation}
  Now we invoke the general KL axiom, which says that this diagram is isomorphic to
  \begin{equation*}
    \left(R[W_i]\stackrel{p_i}{\longleftarrow}R[W_L]\right)_{i\in I}
  \end{equation*}
  By lemma \ref{lm:Rbracket}, this is a limit, since by hypothesis
  \begin{equation*}
   \left(W_i\stackrel{p_i}{\longleftarrow}W_L\right)_{i\in I}
  \end{equation*} 
  is a limit of Weil algebras.
\end{proof}

\subsection{Microlinear objects}

The behavior of \( R \) studied above will be a fundamental requirement as we move onto studying other objects of synthetic differential geometry. We call these objects \emph{microlinear}, and it can be said that they are a sort of generalized ``manifold'' in the context of SDG. Let us state this precisely:

\begin{defn}
  An object \( M \) is said to be \emph{microlinear} if it perceives finite quasi colimits as limits.
\end{defn}

Thus, obviously \( R \) is microlinear. We'll make two observations.

\begin{proposition}
  If \( M \) is a microlinear object and \( X \) is any other object, then \( M^X \) is also microlinear.
\end{proposition}

\clearpage
\bibliography{tfg}
\bibliographystyle{plain}
\end{document}
